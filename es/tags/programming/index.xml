<?xml version="1.0" encoding="utf-8" standalone="yes"?>
<rss version="2.0" xmlns:atom="http://www.w3.org/2005/Atom">
  <channel>
    <title>programming on Gonzalo Silvalde</title>
    <link>https://gonzalosilvalde.github.io/BLOG/es/tags/programming/</link>
    <description>Recent content in programming on Gonzalo Silvalde</description>
    <generator>Hugo -- gohugo.io</generator>
    <lastBuildDate>Mon, 13 Jan 2025 00:00:00 +0000</lastBuildDate><atom:link href="https://gonzalosilvalde.github.io/BLOG/es/tags/programming/index.xml" rel="self" type="application/rss+xml" />
    <item>
      <title>FALSE SHARING</title>
      <link>https://gonzalosilvalde.github.io/BLOG/es/posts/false-sharing/</link>
      <pubDate>Mon, 13 Jan 2025 00:00:00 +0000</pubDate>
      
      <guid>https://gonzalosilvalde.github.io/BLOG/es/posts/false-sharing/</guid>
      <description>El artículo explora el problema de rendimiento conocido como False Sharing, que afecta programas concurrentes debido al acceso compartido a líneas de caché en procesadores modernos. Detalla su impacto, explica cómo identificarlo y presenta diversas estrategias en C para mitigarlo, incluyendo la alineación de datos y el uso de padding. Los resultados muestran cómo pequeños ajustes en la organización de los datos pueden mejorar significativamente el rendimiento, destacando la importancia de optimizar las aplicaciones concurrentes para maximizar la eficiencia del hardware.</description>
      <content>&lt;p&gt;Recientemente, decidí analizar la velocidad de algunos de mis proyectos en C para identificar áreas de mejora. En este proceso, me topé con un concepto que llamó mucho mi atención: el &lt;strong&gt;False Sharing&lt;/strong&gt;.&lt;/p&gt;
&lt;p&gt;El False Sharing es un problema de rendimiento que puede afectar programas concurrentes. Ocurre cuando varios hilos acceden y modifican variables distintas que, por casualidad, comparten la misma línea de caché. Este fenómeno provoca invalidaciones frecuentes de la caché, lo que ralentiza el programa, incluso si las variables no están lógicamente relacionadas entre sí.&lt;/p&gt;
&lt;h3 id=&#34;contexto-técnico&#34;&gt;Contexto Técnico&lt;/h3&gt;
&lt;p&gt;Para entender mejor este problema, es útil considerar cómo los procesadores modernos manejan la memoria:&lt;/p&gt;
&lt;ul&gt;
&lt;li&gt;&lt;strong&gt;Jerarquía de caché&lt;/strong&gt;: Los procesadores tienen niveles de caché (L1, L2, L3) que minimizan la latencia al acceder a la memoria.&lt;/li&gt;
&lt;li&gt;&lt;strong&gt;Líneas de caché&lt;/strong&gt;: La memoria principal está organizada en bloques denominados líneas de caché, que típicamente tienen 64 bytes (aunque este tamaño puede variar según la arquitectura).&lt;/li&gt;
&lt;li&gt;&lt;strong&gt;Acceso y coherencia&lt;/strong&gt;: Cuando un hilo accede a una variable, la línea de caché que la contiene se carga en la caché de la CPU que ejecuta ese hilo. Si otro hilo modifica una variable diferente que se encuentra en la misma línea de caché, toda la línea se invalida en las demás cachés. Esto obliga a recargarla desde la memoria principal o desde la caché que realizó la modificación, impactando negativamente el rendimiento.&lt;/li&gt;
&lt;/ul&gt;
&lt;h2 id=&#34;ejemplo&#34;&gt;EJEMPLO&lt;/h2&gt;
&lt;div class=&#34;highlight&#34;&gt;&lt;pre tabindex=&#34;0&#34; style=&#34;color:#f8f8f2;background-color:#272822;-moz-tab-size:4;-o-tab-size:4;tab-size:4;&#34;&gt;&lt;code class=&#34;language-c&#34; data-lang=&#34;c&#34;&gt;&lt;span style=&#34;display:flex;&#34;&gt;&lt;span&gt;&lt;span style=&#34;color:#75715e&#34;&gt;#include&lt;/span&gt; &lt;span style=&#34;color:#75715e&#34;&gt;&amp;lt;stdio.h&amp;gt;&lt;/span&gt;&lt;span style=&#34;color:#75715e&#34;&gt;
&lt;/span&gt;&lt;/span&gt;&lt;/span&gt;&lt;span style=&#34;display:flex;&#34;&gt;&lt;span&gt;&lt;span style=&#34;color:#75715e&#34;&gt;#include&lt;/span&gt; &lt;span style=&#34;color:#75715e&#34;&gt;&amp;lt;pthread.h&amp;gt;&lt;/span&gt;&lt;span style=&#34;color:#75715e&#34;&gt;
&lt;/span&gt;&lt;/span&gt;&lt;/span&gt;&lt;span style=&#34;display:flex;&#34;&gt;&lt;span&gt;&lt;span style=&#34;color:#75715e&#34;&gt;#include&lt;/span&gt; &lt;span style=&#34;color:#75715e&#34;&gt;&amp;lt;time.h&amp;gt;&lt;/span&gt;&lt;span style=&#34;color:#75715e&#34;&gt;
&lt;/span&gt;&lt;/span&gt;&lt;/span&gt;&lt;span style=&#34;display:flex;&#34;&gt;&lt;span&gt;&lt;span style=&#34;color:#75715e&#34;&gt;&lt;/span&gt;
&lt;/span&gt;&lt;/span&gt;&lt;span style=&#34;display:flex;&#34;&gt;&lt;span&gt;&lt;span style=&#34;color:#75715e&#34;&gt;#define iterations 1000
&lt;/span&gt;&lt;/span&gt;&lt;/span&gt;&lt;span style=&#34;display:flex;&#34;&gt;&lt;span&gt;&lt;span style=&#34;color:#75715e&#34;&gt;&lt;/span&gt;
&lt;/span&gt;&lt;/span&gt;&lt;span style=&#34;display:flex;&#34;&gt;&lt;span&gt;&lt;span style=&#34;color:#66d9ef&#34;&gt;struct&lt;/span&gt; point{
&lt;/span&gt;&lt;/span&gt;&lt;span style=&#34;display:flex;&#34;&gt;&lt;span&gt;    &lt;span style=&#34;color:#66d9ef&#34;&gt;int&lt;/span&gt; x;
&lt;/span&gt;&lt;/span&gt;&lt;span style=&#34;display:flex;&#34;&gt;&lt;span&gt;    &lt;span style=&#34;color:#66d9ef&#34;&gt;int&lt;/span&gt; y;
&lt;/span&gt;&lt;/span&gt;&lt;span style=&#34;display:flex;&#34;&gt;&lt;span&gt;}point;
&lt;/span&gt;&lt;/span&gt;&lt;span style=&#34;display:flex;&#34;&gt;&lt;span&gt;
&lt;/span&gt;&lt;/span&gt;&lt;span style=&#34;display:flex;&#34;&gt;&lt;span&gt;
&lt;/span&gt;&lt;/span&gt;&lt;span style=&#34;display:flex;&#34;&gt;&lt;span&gt;
&lt;/span&gt;&lt;/span&gt;&lt;span style=&#34;display:flex;&#34;&gt;&lt;span&gt;&lt;span style=&#34;color:#66d9ef&#34;&gt;pthread_mutex_t&lt;/span&gt; mutex_x &lt;span style=&#34;color:#f92672&#34;&gt;=&lt;/span&gt; PTHREAD_MUTEX_INITIALIZER;
&lt;/span&gt;&lt;/span&gt;&lt;span style=&#34;display:flex;&#34;&gt;&lt;span&gt;&lt;span style=&#34;color:#66d9ef&#34;&gt;pthread_mutex_t&lt;/span&gt; mutex_y &lt;span style=&#34;color:#f92672&#34;&gt;=&lt;/span&gt; PTHREAD_MUTEX_INITIALIZER;
&lt;/span&gt;&lt;/span&gt;&lt;span style=&#34;display:flex;&#34;&gt;&lt;span&gt;&lt;span style=&#34;color:#66d9ef&#34;&gt;void&lt;/span&gt;&lt;span style=&#34;color:#f92672&#34;&gt;*&lt;/span&gt;
&lt;/span&gt;&lt;/span&gt;&lt;span style=&#34;display:flex;&#34;&gt;&lt;span&gt;&lt;span style=&#34;color:#a6e22e&#34;&gt;sum_x&lt;/span&gt;(&lt;span style=&#34;color:#66d9ef&#34;&gt;void&lt;/span&gt; &lt;span style=&#34;color:#f92672&#34;&gt;*&lt;/span&gt;arg)
&lt;/span&gt;&lt;/span&gt;&lt;span style=&#34;display:flex;&#34;&gt;&lt;span&gt;{
&lt;/span&gt;&lt;/span&gt;&lt;span style=&#34;display:flex;&#34;&gt;&lt;span&gt;    &lt;span style=&#34;color:#66d9ef&#34;&gt;for&lt;/span&gt; (&lt;span style=&#34;color:#66d9ef&#34;&gt;int&lt;/span&gt; i &lt;span style=&#34;color:#f92672&#34;&gt;=&lt;/span&gt; &lt;span style=&#34;color:#ae81ff&#34;&gt;0&lt;/span&gt;; i &lt;span style=&#34;color:#f92672&#34;&gt;&amp;lt;&lt;/span&gt; &lt;span style=&#34;color:#ae81ff&#34;&gt;1000&lt;/span&gt;; i&lt;span style=&#34;color:#f92672&#34;&gt;++&lt;/span&gt;)
&lt;/span&gt;&lt;/span&gt;&lt;span style=&#34;display:flex;&#34;&gt;&lt;span&gt;    {
&lt;/span&gt;&lt;/span&gt;&lt;span style=&#34;display:flex;&#34;&gt;&lt;span&gt;        point.x&lt;span style=&#34;color:#f92672&#34;&gt;++&lt;/span&gt;;
&lt;/span&gt;&lt;/span&gt;&lt;span style=&#34;display:flex;&#34;&gt;&lt;span&gt;    }
&lt;/span&gt;&lt;/span&gt;&lt;span style=&#34;display:flex;&#34;&gt;&lt;span&gt;}    
&lt;/span&gt;&lt;/span&gt;&lt;span style=&#34;display:flex;&#34;&gt;&lt;span&gt;&lt;span style=&#34;color:#66d9ef&#34;&gt;void&lt;/span&gt;&lt;span style=&#34;color:#f92672&#34;&gt;*&lt;/span&gt;
&lt;/span&gt;&lt;/span&gt;&lt;span style=&#34;display:flex;&#34;&gt;&lt;span&gt;&lt;span style=&#34;color:#a6e22e&#34;&gt;sum_y&lt;/span&gt;(&lt;span style=&#34;color:#66d9ef&#34;&gt;void&lt;/span&gt; &lt;span style=&#34;color:#f92672&#34;&gt;*&lt;/span&gt;arg)
&lt;/span&gt;&lt;/span&gt;&lt;span style=&#34;display:flex;&#34;&gt;&lt;span&gt;{
&lt;/span&gt;&lt;/span&gt;&lt;span style=&#34;display:flex;&#34;&gt;&lt;span&gt;    &lt;span style=&#34;color:#66d9ef&#34;&gt;for&lt;/span&gt; (&lt;span style=&#34;color:#66d9ef&#34;&gt;int&lt;/span&gt; i &lt;span style=&#34;color:#f92672&#34;&gt;=&lt;/span&gt; &lt;span style=&#34;color:#ae81ff&#34;&gt;0&lt;/span&gt;; i &lt;span style=&#34;color:#f92672&#34;&gt;&amp;lt;&lt;/span&gt; &lt;span style=&#34;color:#ae81ff&#34;&gt;1000&lt;/span&gt;; i&lt;span style=&#34;color:#f92672&#34;&gt;++&lt;/span&gt;)
&lt;/span&gt;&lt;/span&gt;&lt;span style=&#34;display:flex;&#34;&gt;&lt;span&gt;    {
&lt;/span&gt;&lt;/span&gt;&lt;span style=&#34;display:flex;&#34;&gt;&lt;span&gt;        point.y&lt;span style=&#34;color:#f92672&#34;&gt;++&lt;/span&gt;;
&lt;/span&gt;&lt;/span&gt;&lt;span style=&#34;display:flex;&#34;&gt;&lt;span&gt;    }
&lt;/span&gt;&lt;/span&gt;&lt;span style=&#34;display:flex;&#34;&gt;&lt;span&gt;}
&lt;/span&gt;&lt;/span&gt;&lt;span style=&#34;display:flex;&#34;&gt;&lt;span&gt;
&lt;/span&gt;&lt;/span&gt;&lt;span style=&#34;display:flex;&#34;&gt;&lt;span&gt;&lt;span style=&#34;color:#66d9ef&#34;&gt;int&lt;/span&gt; &lt;span style=&#34;color:#a6e22e&#34;&gt;main&lt;/span&gt;()
&lt;/span&gt;&lt;/span&gt;&lt;span style=&#34;display:flex;&#34;&gt;&lt;span&gt;{
&lt;/span&gt;&lt;/span&gt;&lt;span style=&#34;display:flex;&#34;&gt;&lt;span&gt;    &lt;span style=&#34;color:#66d9ef&#34;&gt;pthread_t&lt;/span&gt; thread1, thread2;
&lt;/span&gt;&lt;/span&gt;&lt;span style=&#34;display:flex;&#34;&gt;&lt;span&gt;
&lt;/span&gt;&lt;/span&gt;&lt;span style=&#34;display:flex;&#34;&gt;&lt;span&gt;    &lt;span style=&#34;color:#66d9ef&#34;&gt;for&lt;/span&gt; (&lt;span style=&#34;color:#66d9ef&#34;&gt;int&lt;/span&gt; iter &lt;span style=&#34;color:#f92672&#34;&gt;=&lt;/span&gt; &lt;span style=&#34;color:#ae81ff&#34;&gt;0&lt;/span&gt;; iter &lt;span style=&#34;color:#f92672&#34;&gt;&amp;lt;&lt;/span&gt; iterations; iter&lt;span style=&#34;color:#f92672&#34;&gt;++&lt;/span&gt;)
&lt;/span&gt;&lt;/span&gt;&lt;span style=&#34;display:flex;&#34;&gt;&lt;span&gt;    {
&lt;/span&gt;&lt;/span&gt;&lt;span style=&#34;display:flex;&#34;&gt;&lt;span&gt;        point.x &lt;span style=&#34;color:#f92672&#34;&gt;=&lt;/span&gt; &lt;span style=&#34;color:#ae81ff&#34;&gt;0&lt;/span&gt;;
&lt;/span&gt;&lt;/span&gt;&lt;span style=&#34;display:flex;&#34;&gt;&lt;span&gt;        point.y &lt;span style=&#34;color:#f92672&#34;&gt;=&lt;/span&gt; &lt;span style=&#34;color:#ae81ff&#34;&gt;0&lt;/span&gt;;
&lt;/span&gt;&lt;/span&gt;&lt;span style=&#34;display:flex;&#34;&gt;&lt;span&gt;
&lt;/span&gt;&lt;/span&gt;&lt;span style=&#34;display:flex;&#34;&gt;&lt;span&gt;        &lt;span style=&#34;color:#a6e22e&#34;&gt;pthread_create&lt;/span&gt;(&lt;span style=&#34;color:#f92672&#34;&gt;&amp;amp;&lt;/span&gt;thread1, NULL, sum_x, NULL);
&lt;/span&gt;&lt;/span&gt;&lt;span style=&#34;display:flex;&#34;&gt;&lt;span&gt;
&lt;/span&gt;&lt;/span&gt;&lt;span style=&#34;display:flex;&#34;&gt;&lt;span&gt;        &lt;span style=&#34;color:#a6e22e&#34;&gt;pthread_create&lt;/span&gt;(&lt;span style=&#34;color:#f92672&#34;&gt;&amp;amp;&lt;/span&gt;thread2, NULL, sum_y, NULL);
&lt;/span&gt;&lt;/span&gt;&lt;span style=&#34;display:flex;&#34;&gt;&lt;span&gt;
&lt;/span&gt;&lt;/span&gt;&lt;span style=&#34;display:flex;&#34;&gt;&lt;span&gt;        &lt;span style=&#34;color:#a6e22e&#34;&gt;pthread_join&lt;/span&gt;(thread1, NULL);
&lt;/span&gt;&lt;/span&gt;&lt;span style=&#34;display:flex;&#34;&gt;&lt;span&gt;
&lt;/span&gt;&lt;/span&gt;&lt;span style=&#34;display:flex;&#34;&gt;&lt;span&gt;        &lt;span style=&#34;color:#a6e22e&#34;&gt;pthread_join&lt;/span&gt;(thread2, NULL);
&lt;/span&gt;&lt;/span&gt;&lt;span style=&#34;display:flex;&#34;&gt;&lt;span&gt;    }
&lt;/span&gt;&lt;/span&gt;&lt;span style=&#34;display:flex;&#34;&gt;&lt;span&gt;    &lt;span style=&#34;color:#a6e22e&#34;&gt;pthread_mutex_destroy&lt;/span&gt;(&lt;span style=&#34;color:#f92672&#34;&gt;&amp;amp;&lt;/span&gt;mutex_x);
&lt;/span&gt;&lt;/span&gt;&lt;span style=&#34;display:flex;&#34;&gt;&lt;span&gt;    &lt;span style=&#34;color:#a6e22e&#34;&gt;pthread_mutex_destroy&lt;/span&gt;(&lt;span style=&#34;color:#f92672&#34;&gt;&amp;amp;&lt;/span&gt;mutex_y);
&lt;/span&gt;&lt;/span&gt;&lt;span style=&#34;display:flex;&#34;&gt;&lt;span&gt;
&lt;/span&gt;&lt;/span&gt;&lt;span style=&#34;display:flex;&#34;&gt;&lt;span&gt;    &lt;span style=&#34;color:#66d9ef&#34;&gt;return&lt;/span&gt; &lt;span style=&#34;color:#ae81ff&#34;&gt;0&lt;/span&gt;;
&lt;/span&gt;&lt;/span&gt;&lt;span style=&#34;display:flex;&#34;&gt;&lt;span&gt;}
&lt;/span&gt;&lt;/span&gt;&lt;/code&gt;&lt;/pre&gt;&lt;/div&gt;&lt;ul&gt;
&lt;li&gt;El hilo 1 actualiza &lt;code&gt;point.x&lt;/code&gt; mientras el hilo 2 actualiza &lt;code&gt;point.y&lt;/code&gt;.&lt;/li&gt;
&lt;li&gt;Aunque &lt;code&gt;point.x&lt;/code&gt; e &lt;code&gt;point.y&lt;/code&gt; son variables independientes, comparten la misma línea de caché.&lt;/li&gt;
&lt;li&gt;Cada vez que un hilo modifica su variable, la línea de caché se invalida en la caché del otro hilo, forzando costosas operaciones de sincronización entre las cachés.&lt;/li&gt;
&lt;/ul&gt;
&lt;p&gt;Esto, trae 3 efectos principales&lt;/p&gt;
&lt;ol&gt;
&lt;li&gt;&lt;strong&gt;Degradación del rendimiento&lt;/strong&gt;: Aumenta la latencia debido a las frecuentes invalidaciones de caché.&lt;/li&gt;
&lt;li&gt;&lt;strong&gt;Mayor uso del bus de memoria&lt;/strong&gt;: Se incrementa la comunicación entre los núcleos del procesador.&lt;/li&gt;
&lt;li&gt;&lt;strong&gt;Dificultad para escalar&lt;/strong&gt;: A medida que se añaden más hilos, el problema puede empeorar.&lt;/li&gt;
&lt;/ol&gt;
&lt;h2 id=&#34;como-mitigar-este-efecto&#34;&gt;¿Como mitigar este efecto?&lt;/h2&gt;
&lt;p&gt;Existen múltiples formas de mitigar el efecto de &lt;strong&gt;false sharing&lt;/strong&gt; en C para este caso concreto. Aquí detallo tres opciones y sus resultados en rendimiento en diferentes optimizaciones:&lt;/p&gt;
&lt;ol&gt;
&lt;li&gt;&lt;strong&gt;Alinear las variables a 64 bytes:&lt;/strong&gt;&lt;/li&gt;
&lt;/ol&gt;
&lt;div class=&#34;highlight&#34;&gt;&lt;pre tabindex=&#34;0&#34; style=&#34;color:#f8f8f2;background-color:#272822;-moz-tab-size:4;-o-tab-size:4;tab-size:4;&#34;&gt;&lt;code class=&#34;language-c&#34; data-lang=&#34;c&#34;&gt;&lt;span style=&#34;display:flex;&#34;&gt;&lt;span&gt;&lt;span style=&#34;color:#66d9ef&#34;&gt;struct&lt;/span&gt; point {
&lt;/span&gt;&lt;/span&gt;&lt;span style=&#34;display:flex;&#34;&gt;&lt;span&gt;    &lt;span style=&#34;color:#66d9ef&#34;&gt;int&lt;/span&gt; x;
&lt;/span&gt;&lt;/span&gt;&lt;span style=&#34;display:flex;&#34;&gt;&lt;span&gt;    &lt;span style=&#34;color:#66d9ef&#34;&gt;int&lt;/span&gt; y &lt;span style=&#34;color:#a6e22e&#34;&gt;__attribute__&lt;/span&gt;((&lt;span style=&#34;color:#a6e22e&#34;&gt;aligned&lt;/span&gt;(&lt;span style=&#34;color:#ae81ff&#34;&gt;64&lt;/span&gt;)));
&lt;/span&gt;&lt;/span&gt;&lt;span style=&#34;display:flex;&#34;&gt;&lt;span&gt;}point;
&lt;/span&gt;&lt;/span&gt;&lt;/code&gt;&lt;/pre&gt;&lt;/div&gt;&lt;p&gt;Esta solución separa las variables en distintas líneas de caché, eliminando el false sharing. Es eficiente en memoria y mejora significativamente el rendimiento.&lt;/p&gt;
&lt;ol start=&#34;2&#34;&gt;
&lt;li&gt;&lt;strong&gt;Alinear el struct completo:&lt;/strong&gt;&lt;/li&gt;
&lt;/ol&gt;
&lt;div class=&#34;highlight&#34;&gt;&lt;pre tabindex=&#34;0&#34; style=&#34;color:#f8f8f2;background-color:#272822;-moz-tab-size:4;-o-tab-size:4;tab-size:4;&#34;&gt;&lt;code class=&#34;language-c&#34; data-lang=&#34;c&#34;&gt;&lt;span style=&#34;display:flex;&#34;&gt;&lt;span&gt;&lt;span style=&#34;color:#66d9ef&#34;&gt;struct&lt;/span&gt; point {
&lt;/span&gt;&lt;/span&gt;&lt;span style=&#34;display:flex;&#34;&gt;&lt;span&gt;    &lt;span style=&#34;color:#66d9ef&#34;&gt;int&lt;/span&gt; x;
&lt;/span&gt;&lt;/span&gt;&lt;span style=&#34;display:flex;&#34;&gt;&lt;span&gt;    &lt;span style=&#34;color:#66d9ef&#34;&gt;int&lt;/span&gt; y;
&lt;/span&gt;&lt;/span&gt;&lt;span style=&#34;display:flex;&#34;&gt;&lt;span&gt;} &lt;span style=&#34;color:#a6e22e&#34;&gt;__attribute__&lt;/span&gt;((&lt;span style=&#34;color:#a6e22e&#34;&gt;aligned&lt;/span&gt;(&lt;span style=&#34;color:#ae81ff&#34;&gt;64&lt;/span&gt;))) point;
&lt;/span&gt;&lt;/span&gt;&lt;/code&gt;&lt;/pre&gt;&lt;/div&gt;&lt;p&gt;Alinea el struct a 64 bytes. Aunque mejora el acceso general, no elimina el false sharing entre &lt;code&gt;x&lt;/code&gt; e &lt;code&gt;y&lt;/code&gt;.&lt;/p&gt;
&lt;ol start=&#34;3&#34;&gt;
&lt;li&gt;&lt;strong&gt;Agregar padding explícito:&lt;/strong&gt;&lt;/li&gt;
&lt;/ol&gt;
&lt;div class=&#34;highlight&#34;&gt;&lt;pre tabindex=&#34;0&#34; style=&#34;color:#f8f8f2;background-color:#272822;-moz-tab-size:4;-o-tab-size:4;tab-size:4;&#34;&gt;&lt;code class=&#34;language-c&#34; data-lang=&#34;c&#34;&gt;&lt;span style=&#34;display:flex;&#34;&gt;&lt;span&gt;&lt;span style=&#34;color:#66d9ef&#34;&gt;struct&lt;/span&gt; point {
&lt;/span&gt;&lt;/span&gt;&lt;span style=&#34;display:flex;&#34;&gt;&lt;span&gt;    &lt;span style=&#34;color:#66d9ef&#34;&gt;int&lt;/span&gt; x;
&lt;/span&gt;&lt;/span&gt;&lt;span style=&#34;display:flex;&#34;&gt;&lt;span&gt;    &lt;span style=&#34;color:#66d9ef&#34;&gt;char&lt;/span&gt; padding[&lt;span style=&#34;color:#ae81ff&#34;&gt;64&lt;/span&gt;];
&lt;/span&gt;&lt;/span&gt;&lt;span style=&#34;display:flex;&#34;&gt;&lt;span&gt;    &lt;span style=&#34;color:#66d9ef&#34;&gt;int&lt;/span&gt; y;
&lt;/span&gt;&lt;/span&gt;&lt;span style=&#34;display:flex;&#34;&gt;&lt;span&gt;}point;
&lt;/span&gt;&lt;/span&gt;&lt;/code&gt;&lt;/pre&gt;&lt;/div&gt;&lt;p&gt;Separa físicamente &lt;code&gt;x&lt;/code&gt; e &lt;code&gt;y&lt;/code&gt; en memoria. Aunque elimina el false sharing, incrementa el uso de memoria y puede afectar negativamente el rendimiento.&lt;/p&gt;
&lt;ol start=&#34;4&#34;&gt;
&lt;li&gt;&lt;strong&gt;Usar variables globales independientes:&lt;/strong&gt;&lt;/li&gt;
&lt;/ol&gt;
&lt;div class=&#34;highlight&#34;&gt;&lt;pre tabindex=&#34;0&#34; style=&#34;color:#f8f8f2;background-color:#272822;-moz-tab-size:4;-o-tab-size:4;tab-size:4;&#34;&gt;&lt;code class=&#34;language-c&#34; data-lang=&#34;c&#34;&gt;&lt;span style=&#34;display:flex;&#34;&gt;&lt;span&gt;&lt;span style=&#34;color:#66d9ef&#34;&gt;int&lt;/span&gt; x;
&lt;/span&gt;&lt;/span&gt;&lt;span style=&#34;display:flex;&#34;&gt;&lt;span&gt;&lt;span style=&#34;color:#66d9ef&#34;&gt;int&lt;/span&gt; y;
&lt;/span&gt;&lt;/span&gt;&lt;/code&gt;&lt;/pre&gt;&lt;/div&gt;&lt;p&gt;Evita el false sharing, pero no siempre es práctico.&lt;/p&gt;
&lt;h3 id=&#34;análisis-de-rendimiento&#34;&gt;Análisis de Rendimiento&lt;/h3&gt;
&lt;p&gt;Usando perf, analicé el impacto de cada solución:&lt;/p&gt;
&lt;blockquote&gt;
&lt;p&gt;perf record -o perf_programa1.data ./programa&lt;br&gt;
perf report -i perf_programa1.data&lt;/p&gt;
&lt;/blockquote&gt;
&lt;h3 id=&#34;caso-base&#34;&gt;Caso Base&lt;/h3&gt;
&lt;p&gt;El reporte de &lt;code&gt;perf&lt;/code&gt; se ve así:&lt;/p&gt;
&lt;blockquote&gt;
&lt;p&gt;8,72%  prueba1  libc.so.6             [.] pthread_mutex_lock@@GLIBC_2.2.5&lt;br&gt;
7,75%  prueba1  [kernel.kallsyms]     [k] memset&lt;br&gt;
5,79%  prueba1  libc.so.6             [.] __GI___pthread_mutex_unlock_usercnt&lt;br&gt;
3,25%  prueba1  [kernel.kallsyms]     [k] clear_page_rep&lt;br&gt;
2,78%  prueba1  [kernel.kallsyms]     [k] unmap_page_range&lt;br&gt;
2,46%  prueba1  [kernel.kallsyms]     [k] native_queued_spin_lock_slowpath&lt;br&gt;
2,11%  prueba1  [kernel.kallsyms]     [k] native_write_msr&lt;br&gt;
1,45%  prueba1  [kernel.kallsyms]     [k] psi_group_change&lt;/p&gt;
&lt;/blockquote&gt;
&lt;h3 id=&#34;caso-con-alineación-y&#34;&gt;Caso con alineación &lt;code&gt;y&lt;/code&gt;&lt;/h3&gt;
&lt;p&gt;Al alinear &lt;code&gt;y&lt;/code&gt; a 64 bytes, el false sharing desaparece:&lt;/p&gt;
&lt;blockquote&gt;
&lt;p&gt;19,27%  prueba2  libc.so.6             [.] pthread_mutex_lock@@GLIBC_2.2.5&lt;br&gt;
19,15%  prueba2  libc.so.6             [.] __GI___pthread_mutex_unlock_usercnt&lt;br&gt;
10,31%  prueba2  [kernel.kallsyms]     [k] memset&lt;br&gt;
9,63%  prueba2  [kernel.kallsyms]     [k] clear_page_rep&lt;br&gt;
5,38%  prueba2  [kernel.kallsyms]     [k] native_write_msr&lt;br&gt;
1,98%  prueba2  [kernel.kallsyms]     [k] __list_del_entry_valid&lt;br&gt;
1,29%  prueba2  [kernel.kallsyms]     [k] copy_process&lt;br&gt;
1,20%  prueba2  [kernel.kallsyms]     [k] __memcg_kmem_charge_page&lt;br&gt;
1,20%  prueba2  [kernel.kallsyms]     [k] alloc_vmap_area&lt;br&gt;
1,06%  prueba2  [kernel.kallsyms]     [k] memcpy&lt;br&gt;
0,85%  prueba2  prueba2               [.] sum_x&lt;br&gt;
0,84%  prueba2  [kernel.kallsyms]     [k] try_charge_memcg&lt;/p&gt;
&lt;/blockquote&gt;
&lt;p&gt;La sincronización explícita domina el uso de recursos, eliminando cuellos de botella en la caché.&lt;/p&gt;
&lt;h3 id=&#34;caso-alineación-struct-completo&#34;&gt;Caso alineación struct completo&lt;/h3&gt;
&lt;p&gt;Alinear el struct completo no elimina el false sharing entre x e y porque permanecen en la misma línea de caché:&lt;/p&gt;
&lt;blockquote&gt;
&lt;p&gt;19,74%  prueba4  libc.so.6             [.] pthread_mutex_lock@@GLIBC_2.2.5&lt;br&gt;
19,24%  prueba4  libc.so.6             [.] __GI___pthread_mutex_unlock_usercnt&lt;br&gt;
5,86%  prueba4  [kernel.kallsyms]     [k] native_write_msr&lt;br&gt;
5,85%  prueba4  [kernel.kallsyms]     [k] memset&lt;br&gt;
2,59%  prueba4  [kernel.kallsyms]     [k] clear_page_rep&lt;br&gt;
2,05%  prueba4  [kernel.kallsyms]     [k] unmap_page_range&lt;br&gt;
1,31%  prueba4  [kernel.kallsyms]     [k] psi_group_change&lt;br&gt;
1,26%  prueba4  [kernel.kallsyms]     [k] memcpy&lt;br&gt;
0,95%  prueba4  [kernel.kallsyms]     [k] copy_process&lt;br&gt;
0,86%  prueba4  [kernel.kallsyms]     [k] native_read_msr&lt;br&gt;
0,84%  prueba4  [kernel.kallsyms]     [k] memcg_slab_post_alloc_hook&lt;br&gt;
0,84%  prueba4  prueba4               [.] sum_x&lt;br&gt;
0,83%  prueba4  [kernel.kallsyms]     [k] retbleed_return_thunk&lt;/p&gt;
&lt;/blockquote&gt;
&lt;p&gt;Aunque mejora ligeramente el rendimiento general al optimizar el acceso global al struct, el false sharing persiste, limitando las ganancias.&lt;/p&gt;
&lt;h2 id=&#34;caso-con-padding-explícito&#34;&gt;Caso con Padding explícito&lt;/h2&gt;
&lt;p&gt;Agregar padding explícito elimina el false sharing, pero introduce costos adicionales por el mayor tamaño del struct:&lt;/p&gt;
&lt;blockquote&gt;
&lt;p&gt;22,11%  prueba5  libc.so.6             [.] pthread_mutex_lock@@GLIBC_2.2.5&lt;br&gt;
21,95%  prueba5  libc.so.6             [.] __GI___pthread_mutex_unlock_usercnt&lt;br&gt;
7,58%  prueba5  [kernel.kallsyms]     [k] native_write_msr&lt;br&gt;
5,12%  prueba5  [kernel.kallsyms]     [k] memset&lt;br&gt;
2,57%  prueba5  [kernel.kallsyms]     [k] clear_page_rep&lt;br&gt;
1,50%  prueba5  [kernel.kallsyms]     [k] copy_process&lt;br&gt;
1,40%  prueba5  [kernel.kallsyms]     [k] psi_group_change&lt;br&gt;
1,05%  prueba5  [kernel.kallsyms]     [k] native_read_msr&lt;br&gt;
0,89%  prueba5  prueba5               [.] sum_x&lt;br&gt;
0,81%  prueba5  [kernel.kallsyms]     [k] retbleed_return_thunk&lt;br&gt;
0,76%  prueba5  [kernel.kallsyms]     [k] ___slab_alloc&lt;br&gt;
0,74%  prueba5  [kernel.kallsyms]     [k] _raw_spin_lock&lt;/p&gt;
&lt;/blockquote&gt;
&lt;p&gt;El aumento en el uso de memoria reduce la densidad de datos en caché, penalizando el prefetching y limitando las mejoras.&lt;/p&gt;
&lt;h3 id=&#34;caso-con-variables-independientes&#34;&gt;Caso con Variables Independientes&lt;/h3&gt;
&lt;p&gt;El uso de variables globales independientes elimina el false sharing, pero el rendimiento no mejora significativamente:&lt;/p&gt;
&lt;blockquote&gt;
&lt;p&gt;32,54%  prueba6  libc.so.6             [.] __GI___pthread_mutex_unlock_usercnt&lt;br&gt;
21,81%  prueba6  libc.so.6             [.] pthread_mutex_lock@@GLIBC_2.2.5&lt;br&gt;
6,89%  prueba6  [kernel.kallsyms]     [k] memset&lt;br&gt;
5,90%  prueba6  prueba6               [.] sum_y&lt;br&gt;
4,81%  prueba6  [kernel.kallsyms]     [k] native_write_msr&lt;br&gt;
1,00%  prueba6  [kernel.kallsyms]     [k] _raw_spin_lock&lt;br&gt;
0,97%  prueba6  [kernel.kallsyms]     [k] clear_page_rep&lt;/p&gt;
&lt;/blockquote&gt;
&lt;p&gt;Esto se debe a la sobrecarga de sincronización explícita y a la latencia de acceso a memoria global.&lt;/p&gt;
&lt;h3 id=&#34;conclusión-de-perf&#34;&gt;Conclusión de &lt;code&gt;perf&lt;/code&gt;&lt;/h3&gt;
&lt;p&gt;El análisis de los resultados obtenidos con &lt;code&gt;perf&lt;/code&gt; y los tiempos medidos para las diferentes configuraciones revela cómo afectan las estrategias de alineación y diseño de datos al rendimiento, explicando el impacto en cada caso.&lt;/p&gt;
&lt;p&gt;En el caso base, las variables &lt;code&gt;x&lt;/code&gt; e &lt;code&gt;y&lt;/code&gt; están en el mismo struct sin ninguna alineación específica. Esto provoca que compartan la misma línea de caché, lo que genera false sharing cuando los hilos acceden concurrentemente a estas variables. El reporte de &lt;code&gt;perf&lt;/code&gt; muestra un uso significativo de funciones relacionadas con la sincronización, como &lt;code&gt;native_queued_spin_lock_slowpath&lt;/code&gt; y &lt;code&gt;memset&lt;/code&gt;, indicando que los hilos están invalidando constantemente las líneas de caché. Este comportamiento explica el tiempo relativamente alto de ejecución (123.93 segundos), pues el false sharing genera una gran sobrecarga.&lt;/p&gt;
&lt;p&gt;Cuando se alinea la variable &lt;code&gt;y&lt;/code&gt; a 64 bytes, el false sharing se elimina, ya que &lt;code&gt;x&lt;/code&gt; e &lt;code&gt;y&lt;/code&gt; pasan a ocupar líneas de caché diferentes. Esto se traduce en una mejora notable en el tiempo de ejecución (83.21 segundos). El reporte de &lt;code&gt;perf&lt;/code&gt; muestra que funciones como &lt;code&gt;native_queued_spin_lock_slowpath&lt;/code&gt; desaparecen, mientras que &lt;code&gt;pthread_mutex_lock&lt;/code&gt; y &lt;code&gt;pthread_mutex_unlock&lt;/code&gt; dominan el consumo de ciclos, reflejando que la sincronización explícita es ahora el mayor costo. Esta configuración resulta ser la más eficiente, ya que elimina el cuello de botella del false sharing sin introducir una sobrecarga significativa.&lt;/p&gt;
&lt;p&gt;En este caso, no hay evidencia de false sharing en el reporte de &lt;code&gt;perf&lt;/code&gt;, ya que no aparece &lt;code&gt;native_queued_spin_lock_slowpath&lt;/code&gt; ni otros indicadores claros de contención en la caché. Sin embargo, alinear el &lt;code&gt;struct&lt;/code&gt; completo a 64 bytes no elimina el false sharing entre &lt;code&gt;x&lt;/code&gt; e &lt;code&gt;y&lt;/code&gt;, ya que ambas variables permanecen en la misma línea de caché. Esto mejora ligeramente el rendimiento global al optimizar el acceso al &lt;code&gt;struct&lt;/code&gt;, pero el false sharing persiste, limitando las ganancias. El rendimiento es un poco peor que alinear solo las variables individuales, probablemente debido al mayor uso de memoria, lo que aumenta la presión sobre la caché. Además, las funciones de sincronización, como &lt;code&gt;pthread_mutex_lock&lt;/code&gt; y &lt;code&gt;pthread_mutex_unlock&lt;/code&gt;, son los principales cuellos de botella, indicando que el problema está más relacionado con la sincronización que con la organización de los datos.&lt;/p&gt;
&lt;p&gt;Cuando se utiliza padding explícito para separar &lt;code&gt;x&lt;/code&gt; e &lt;code&gt;y&lt;/code&gt; en memoria, el false sharing desaparece. Sin embargo, esta estrategia introduce un costo adicional debido al aumento en el tamaño del struct, lo que reduce la densidad de datos en caché y dificulta el prefetching. Esto resulta en el peor rendimiento observado (127.01 segundos). El análisis de &lt;code&gt;perf&lt;/code&gt; confirma que, aunque el false sharing se elimina, el tiempo sigue dominado por funciones de sincronización (&lt;code&gt;pthread_mutex_lock&lt;/code&gt; y &lt;code&gt;pthread_mutex_unlock&lt;/code&gt;), lo que limita las mejoras.&lt;/p&gt;
&lt;p&gt;Finalmente, al usar variables globales independientes en lugar de un struct, el false sharing debería desaparecer. Sin embargo, el rendimiento obtenido (124.81 segundos) es comparable al caso base. El reporte de &lt;code&gt;perf&lt;/code&gt; indica que la alta proporción de tiempo en &lt;code&gt;pthread_mutex_lock&lt;/code&gt; y &lt;code&gt;pthread_mutex_unlock&lt;/code&gt; refleja la sobrecarga de sincronización explícita. Además, aunque se elimina la invalidación de caché, el acceso global puede introducir pequeñas penalizaciones debido a la latencia de acceso a memoria, lo que explica la falta de mejora significativa.&lt;/p&gt;
&lt;h3 id=&#34;resultados&#34;&gt;Resultados&lt;/h3&gt;
&lt;p&gt;En este apartado muestro los resultados de la velocidad en segundos que tardo el programa con las diferentes formas de declarar las variables en 1000000 de iteraciones y con distintos tipos de optimización.&lt;/p&gt;
&lt;p&gt;-O0:&lt;/p&gt;
&lt;table&gt;
&lt;thead&gt;
&lt;tr&gt;
&lt;th&gt;configuración&lt;/th&gt;
&lt;th&gt;nº iteraciones&lt;/th&gt;
&lt;th&gt;velocidad (s)&lt;/th&gt;
&lt;/tr&gt;
&lt;/thead&gt;
&lt;tbody&gt;
&lt;tr&gt;
&lt;td&gt;Caso base&lt;/td&gt;
&lt;td&gt;1000000&lt;/td&gt;
&lt;td&gt;123.933620&lt;/td&gt;
&lt;/tr&gt;
&lt;tr&gt;
&lt;td&gt;Alinear  &lt;code&gt;y&lt;/code&gt;&lt;/td&gt;
&lt;td&gt;1000000&lt;/td&gt;
&lt;td&gt;83.217787&lt;/td&gt;
&lt;/tr&gt;
&lt;tr&gt;
&lt;td&gt;Alinear struct completo&lt;/td&gt;
&lt;td&gt;1000000&lt;/td&gt;
&lt;td&gt;99.541299&lt;/td&gt;
&lt;/tr&gt;
&lt;tr&gt;
&lt;td&gt;Padding explícito ( &lt;code&gt;char[64]&lt;/code&gt;)&lt;/td&gt;
&lt;td&gt;1000000&lt;/td&gt;
&lt;td&gt;127.010401&lt;/td&gt;
&lt;/tr&gt;
&lt;tr&gt;
&lt;td&gt;Variables fuera del struct&lt;/td&gt;
&lt;td&gt;1000000&lt;/td&gt;
&lt;td&gt;124.819451&lt;/td&gt;
&lt;/tr&gt;
&lt;/tbody&gt;
&lt;/table&gt;
&lt;p&gt;-O1:&lt;/p&gt;
&lt;table&gt;
&lt;thead&gt;
&lt;tr&gt;
&lt;th&gt;configuración&lt;/th&gt;
&lt;th&gt;nº iteraciones&lt;/th&gt;
&lt;th&gt;velocidad (s)&lt;/th&gt;
&lt;/tr&gt;
&lt;/thead&gt;
&lt;tbody&gt;
&lt;tr&gt;
&lt;td&gt;Caso base&lt;/td&gt;
&lt;td&gt;1000000&lt;/td&gt;
&lt;td&gt;120.383218&lt;/td&gt;
&lt;/tr&gt;
&lt;tr&gt;
&lt;td&gt;Alinear  &lt;code&gt;y&lt;/code&gt;&lt;/td&gt;
&lt;td&gt;1000000&lt;/td&gt;
&lt;td&gt;79.891089&lt;/td&gt;
&lt;/tr&gt;
&lt;tr&gt;
&lt;td&gt;Alinear struct completo&lt;/td&gt;
&lt;td&gt;1000000&lt;/td&gt;
&lt;td&gt;104.526728&lt;/td&gt;
&lt;/tr&gt;
&lt;tr&gt;
&lt;td&gt;Padding explícito ( &lt;code&gt;char[64]&lt;/code&gt;)&lt;/td&gt;
&lt;td&gt;1000000&lt;/td&gt;
&lt;td&gt;79.828506&lt;/td&gt;
&lt;/tr&gt;
&lt;tr&gt;
&lt;td&gt;Variables fuera del struct&lt;/td&gt;
&lt;td&gt;1000000&lt;/td&gt;
&lt;td&gt;105.029095&lt;/td&gt;
&lt;/tr&gt;
&lt;/tbody&gt;
&lt;/table&gt;
&lt;p&gt;-O2:&lt;/p&gt;
&lt;table&gt;
&lt;thead&gt;
&lt;tr&gt;
&lt;th&gt;configuración&lt;/th&gt;
&lt;th&gt;nº iteraciones&lt;/th&gt;
&lt;th&gt;velocidad (s)&lt;/th&gt;
&lt;/tr&gt;
&lt;/thead&gt;
&lt;tbody&gt;
&lt;tr&gt;
&lt;td&gt;Caso base&lt;/td&gt;
&lt;td&gt;1000000&lt;/td&gt;
&lt;td&gt;120.622384&lt;/td&gt;
&lt;/tr&gt;
&lt;tr&gt;
&lt;td&gt;Alinear  &lt;code&gt;y&lt;/code&gt;&lt;/td&gt;
&lt;td&gt;1000000&lt;/td&gt;
&lt;td&gt;80.128776&lt;/td&gt;
&lt;/tr&gt;
&lt;tr&gt;
&lt;td&gt;Alinear struct completo&lt;/td&gt;
&lt;td&gt;1000000&lt;/td&gt;
&lt;td&gt;103.547142&lt;/td&gt;
&lt;/tr&gt;
&lt;tr&gt;
&lt;td&gt;Padding explícito ( &lt;code&gt;char[64]&lt;/code&gt;)&lt;/td&gt;
&lt;td&gt;1000000&lt;/td&gt;
&lt;td&gt;79.989479&lt;/td&gt;
&lt;/tr&gt;
&lt;tr&gt;
&lt;td&gt;Variables fuera del struct&lt;/td&gt;
&lt;td&gt;1000000&lt;/td&gt;
&lt;td&gt;103.280250&lt;/td&gt;
&lt;/tr&gt;
&lt;/tbody&gt;
&lt;/table&gt;
&lt;p&gt;-O3:&lt;/p&gt;
&lt;table&gt;
&lt;thead&gt;
&lt;tr&gt;
&lt;th&gt;configuración&lt;/th&gt;
&lt;th&gt;nº iteraciones&lt;/th&gt;
&lt;th&gt;velocidad (s)&lt;/th&gt;
&lt;/tr&gt;
&lt;/thead&gt;
&lt;tbody&gt;
&lt;tr&gt;
&lt;td&gt;Caso base&lt;/td&gt;
&lt;td&gt;1000000&lt;/td&gt;
&lt;td&gt;120.887245&lt;/td&gt;
&lt;/tr&gt;
&lt;tr&gt;
&lt;td&gt;Alinear  &lt;code&gt;y&lt;/code&gt;&lt;/td&gt;
&lt;td&gt;1000000&lt;/td&gt;
&lt;td&gt;79.762786&lt;/td&gt;
&lt;/tr&gt;
&lt;tr&gt;
&lt;td&gt;Alinear struct completo&lt;/td&gt;
&lt;td&gt;1000000&lt;/td&gt;
&lt;td&gt;103.815620&lt;/td&gt;
&lt;/tr&gt;
&lt;tr&gt;
&lt;td&gt;Padding explícito ( &lt;code&gt;char[64]&lt;/code&gt;)&lt;/td&gt;
&lt;td&gt;1000000&lt;/td&gt;
&lt;td&gt;79.586391&lt;/td&gt;
&lt;/tr&gt;
&lt;tr&gt;
&lt;td&gt;Variables fuera del struct&lt;/td&gt;
&lt;td&gt;1000000&lt;/td&gt;
&lt;td&gt;101.085188&lt;/td&gt;
&lt;/tr&gt;
&lt;/tbody&gt;
&lt;/table&gt;
&lt;h3 id=&#34;por-qué-las-optimizaciones-desde--o1-mejoran-el-tiempo-de-ejecución&#34;&gt;¿Por qué las optimizaciones desde -O1 mejoran el tiempo de ejecución?&lt;/h3&gt;
&lt;p&gt;Cuando un programa se compila con optimizaciones a partir de &lt;code&gt;-O1&lt;/code&gt;, el compilador comienza a realizar ajustes fundamentales que mejoran significativamente el rendimiento. En este nivel, se eliminan cálculos redundantes, se reorganizan las instrucciones para aprovechar mejor los recursos de la CPU y se optimizan los accesos a memoria, reduciendo la latencia. Estos cambios automáticos complementan las optimizaciones manuales, como la alineación de datos, al permitir que el hardware trabaje con mayor eficiencia, especialmente en casos donde problemas como el false sharing han sido mitigados.&lt;/p&gt;
&lt;p&gt;A niveles más altos de optimización, como &lt;code&gt;-O2&lt;/code&gt; y &lt;code&gt;-O3&lt;/code&gt;, el compilador introduce técnicas más avanzadas, como la vectorización, la eliminación agresiva de ramas y el inlining de funciones, que reducen aún más la sobrecarga asociada a la ejecución. Sin embargo, el impacto en tiempos de ejecución se estabiliza, ya que el cuello de botella principal (como la sincronización explícita en programas multihilo) no siempre puede eliminarse solo con optimización del código. Esto destaca la importancia de combinar un diseño cuidadoso de datos con las capacidades del compilador para lograr el mejor rendimiento posible.&lt;/p&gt;
&lt;h3 id=&#34;reflexión-final&#34;&gt;Reflexión Final&lt;/h3&gt;
&lt;p&gt;El rendimiento en aplicaciones concurrentes está profundamente ligado a la forma en que los datos se estructuran y acceden en memoria. Como hemos visto, problemas como el False Sharing pueden surgir de pequeños descuidos en el diseño de estructuras de datos, pero tienen un impacto desproporcionado en el desempeño. Afortunadamente, con un enfoque metódico y herramientas como &lt;code&gt;perf&lt;/code&gt;, es posible identificar estos problemas y abordarlos con optimizaciones simples pero efectivas.&lt;/p&gt;
&lt;p&gt;Este artículo refleja mi entendimiento actual sobre el tema y mi intención de compartir conocimientos útiles. Sin embargo, si hay algo que pueda mejorarse, corregirse o ampliarse, estaré encantado de recibir tu retroalimentación. No dudes en contactarme por correo para compartir tus comentarios, experiencias o cualquier corrección que consideres necesaria.&lt;/p&gt;
&lt;hr&gt;
&lt;h3 id=&#34;sumario-de-términos&#34;&gt;Sumario de términos:&lt;/h3&gt;
&lt;ul&gt;
&lt;li&gt;&lt;strong&gt;False Sharing&lt;/strong&gt;: Ocurre cuando múltiples hilos acceden a variables diferentes que comparten la misma línea de caché. Esto genera conflictos innecesarios en la memoria caché, degradando el rendimiento.&lt;/li&gt;
&lt;li&gt;&lt;strong&gt;Línea de caché&lt;/strong&gt;: Unidad mínima de datos que la caché de la CPU intercambia con la memoria principal. Su tamaño suele ser de 64 bytes en la mayoría de los procesadores modernos.&lt;/li&gt;
&lt;li&gt;&lt;strong&gt;Alineación de datos&lt;/strong&gt;: Técnica que organiza los datos en memoria de manera que coincidan con los límites de línea de caché, minimizando conflictos entre hilos.&lt;/li&gt;
&lt;li&gt;&lt;strong&gt;Padding&lt;/strong&gt;: Proceso de agregar bytes adicionales entre elementos de una estructura de datos para evitar que compartan líneas de caché.&lt;/li&gt;
&lt;li&gt;&lt;strong&gt;Optimización del compilador&lt;/strong&gt;: Ajustes automáticos realizados por el compilador en diferentes niveles (&lt;code&gt;-O1&lt;/code&gt;, &lt;code&gt;-O2&lt;/code&gt;, &lt;code&gt;-O3&lt;/code&gt;) para mejorar el rendimiento de un programa sin alterar su funcionalidad.&lt;/li&gt;
&lt;li&gt;&lt;strong&gt;Prefetching&lt;/strong&gt;: Técnica usada por los procesadores para cargar datos en caché antes de que sean necesarios, reduciendo la latencia de acceso.&lt;/li&gt;
&lt;li&gt;&lt;strong&gt;Sincronización explícita&lt;/strong&gt;: Uso de primitivas como mutex o semáforos para coordinar el acceso a recursos compartidos entre hilos.&lt;/li&gt;
&lt;li&gt;&lt;strong&gt;Densidad de datos en caché&lt;/strong&gt;: Cantidad de datos útiles que pueden ser almacenados en la caché simultáneamente; afecta el rendimiento general en sistemas que dependen de la velocidad de acceso a la memoria.&lt;/li&gt;
&lt;/ul&gt;
</content>
    </item>
    
    <item>
      <title>Primeros pasos en ADA</title>
      <link>https://gonzalosilvalde.github.io/BLOG/es/posts/ada-introduction/</link>
      <pubDate>Thu, 07 Nov 2024 00:00:00 +0000</pubDate>
      
      <guid>https://gonzalosilvalde.github.io/BLOG/es/posts/ada-introduction/</guid>
      <description>Un acercamiento práctico a Ada, un lenguaje poco común pero poderoso, ideal para sistemas de alta seguridad. Desde conceptos básicos hasta desafíos avanzados, descubre cómo empecé a experimentar con sus funciones y herramientas.</description>
      <content>&lt;h2 id=&#34;ada&#34;&gt;ADA&lt;/h2&gt;
&lt;h1 id=&#34;introducción&#34;&gt;Introducción&lt;/h1&gt;
&lt;p&gt;Hace unas semanas, un compañero me mencionó Ada, un lenguaje que conocía vagamente por su rapidez y sus aplicaciones en la industria aeroespacial, especialmente en el desarrollo de aviones. Con este mínimo conocimiento, me adentré en el mundo de Ada.&lt;/p&gt;
&lt;p&gt;Mi curiosidad creció al notar la escasez de recursos informales para aprender el lenguaje, como videos o tutoriales básicos. Encontré listas de reproducción en YouTube incompletas y blogs que solo llegaban a cubrir temas básicos como bucles. Sorprendentemente, ni siquiera encontré cursos en plataformas populares como Udemy o Coursera. Esto podría desanimar a cualquiera, pero en mi caso, me lo tomé como un reto y decidí explorar este lenguaje tan poco mainstream.&lt;/p&gt;
&lt;h1 id=&#34;primeros-pasos&#34;&gt;Primeros pasos&lt;/h1&gt;
&lt;p&gt;Como suele ser habitual al aprender un nuevo lenguaje, lo primero que hice fue acudir a la &lt;a href=&#34;https://www.adacore.com/documentation#all&#34;&gt;documentación oficial&lt;/a&gt;. Con un manual de referencia y la guía de &lt;a href=&#34;https://www.adacore.com/documentation#all&#34;&gt;AdaCore&lt;/a&gt; en mano, empecé a dar mis primeros pasos.&lt;/p&gt;
&lt;h3 id=&#34;hola-mundohttpsgithubcomgonzalosilvaldeadatreehola_mundo&#34;&gt;&lt;a href=&#34;https://github.com/Gonzalosilvalde/ADA/tree/Hola_mundo&#34;&gt;HOLA MUNDO&lt;/a&gt;&lt;/h3&gt;
&lt;p&gt;La primera impresión que me llevé al escribir un &lt;code&gt;hola mundo&lt;/code&gt; fue que Ada tenía un estilo algo rústico, similar a &lt;code&gt;Pascal&lt;/code&gt;, con sus &lt;code&gt;procedures&lt;/code&gt;, &lt;code&gt;begin&lt;/code&gt; y &lt;code&gt;end&lt;/code&gt;. También noté un formato de indentación parecido al de Python. No encontré aquí la complejidad que a veces aparece en otros lenguajes, como Java, al escribir un programa simple. Esto me dio confianza para continuar.&lt;/p&gt;
&lt;h3 id=&#34;funcioneshttpsgithubcomgonzalosilvaldeadatreefunctions&#34;&gt;&lt;a href=&#34;https://github.com/Gonzalosilvalde/ADA/tree/Functions&#34;&gt;Funciones&lt;/a&gt;&lt;/h3&gt;
&lt;p&gt;Con un poco de confianza, decidí avanzar rápidamente y me sumergí en el tema de las funciones. Aquí también Ada me recordó a &lt;code&gt;Pascal&lt;/code&gt;, especialmente con la distinción entre &lt;code&gt;procedure&lt;/code&gt; (que no devuelve nada) y &lt;code&gt;function&lt;/code&gt; (que sí devuelve un valor). La diferencia está en que, en Ada, el tipo de retorno se coloca al final de la función, en contraste con lenguajes como &lt;code&gt;C&lt;/code&gt;, donde aparece al principio. Implementé algunas funciones simples para operaciones matemáticas básicas, sin demasiadas sorpresas en este apartado.&lt;/p&gt;
&lt;h3 id=&#34;recursividadhttpsgithubcomgonzalosilvaldeadatreerecursion&#34;&gt;&lt;a href=&#34;https://github.com/Gonzalosilvalde/ADA/tree/recursion&#34;&gt;Recursividad&lt;/a&gt;&lt;/h3&gt;
&lt;p&gt;Aunque la recursividad no suele ser popular entre los programadores, siempre he encontrado algo estéticamente interesante en su uso, y es un tema que suelo probar al aprender un lenguaje nuevo.&lt;/p&gt;
&lt;p&gt;La recursividad en Ada no presentó problemas, hasta que intenté calcular números altos en la sucesión de Fibonacci. Para números pequeños, todo funcionaba bien; sin embargo, al llegar a valores más altos, encontré un error debido a la limitación en el tamaño de los enteros. Buscando una solución, descubrí el paquete &lt;a href=&#34;https://learn.adacore.com/courses/whats-new-in-ada-2022/chapters/big_numbers.html&#34;&gt;Big Numbers&lt;/a&gt;, pero al intentar compilarlo, me apareció un error indicando que el paquete no existía. Esto me llevó a investigar Alire, el gestor de paquetes de Ada, y aunque no solucionó mi problema en ese momento, fue mi primera introducción a esta herramienta.&lt;/p&gt;
&lt;h3 id=&#34;alirehttpsalireadadev&#34;&gt;&lt;a href=&#34;https://alire.ada.dev/&#34;&gt;Alire&lt;/a&gt;&lt;/h3&gt;
&lt;p&gt;En mi &lt;a href=&#34;https://github.com/Gonzalosilvalde/ADA/tree/main&#34;&gt;repositorio&lt;/a&gt; hay una rama llamada &amp;ldquo;Alire&amp;rdquo;, aunque realmente aún no he profundizado en el uso de este gestor de paquetes. A continuación, te comparto mis primeras impresiones sobre Alire.&lt;/p&gt;
&lt;p&gt;Para empezar, Alire es un gestor de paquetes para Ada. Si tienes experiencia con Rust, notarás rápidamente que Alire es comparable a Cargo, aunque con algunas diferencias que lo hacen interesante. Sin embargo, la comunidad de Alire es relativamente pequeña, y eso se refleja en la cantidad y variedad de paquetes disponibles. Al explorar la lista de crates en &lt;a href=&#34;https://alire.ada.dev/crates.html&#34;&gt;su sitio web&lt;/a&gt;, da la sensación de que muchos paquetes son demasiado específicos, y la falta de una comunidad grande y diversa limita las opciones y la amplitud de aplicaciones.&lt;/p&gt;
&lt;p&gt;Al comparar con &lt;a href=&#34;https://crates.io/&#34;&gt;crates.io&lt;/a&gt; de Cargo, la diferencia es clara. La web de Cargo es mucho más amigable, con un buscador avanzado y etiquetas que facilitan encontrar paquetes de interés, sin depender tanto del nombre o de una descripción exacta. En Alire, el buscador a veces resulta menos eficiente, y la navegación entre las categorías no es tan intuitiva; aunque, curiosamente, usar &lt;code&gt;ctrl + f&lt;/code&gt; y las etiquetas manualmente puede resultar más práctico.&lt;/p&gt;
&lt;p&gt;Además, he experimentado algunos inconvenientes al compilar con Alire. Aunque agradezco los errores de programación y advertencias importantes, los warnings de estilo a veces pueden resultar excesivos, sobre todo en proyectos personales donde no es tan relevante seguir un formato específico. Entiendo que este tipo de advertencias pueden ser útiles para aprender las convenciones del lenguaje, pero en mi caso, prefiero enfocarme en la funcionalidad antes que en el estilo. Quizás exista alguna forma de desactivar estos warnings de estilo, pero aún no he investigado a fondo.&lt;/p&gt;
&lt;p&gt;En resumen, creo que Alire tiene potencial, pero la falta de comunidad limita el desarrollo de un ecosistema más amplio y robusto. Con una comunidad más activa, seguramente estas limitaciones se irían superando gradualmente.&lt;/p&gt;
&lt;h3 id=&#34;semáforoshttpsgithubcomgonzalosilvaldeadatreealire&#34;&gt;&lt;a href=&#34;https://github.com/Gonzalosilvalde/ADA/tree/alire&#34;&gt;Semáforos&lt;/a&gt;&lt;/h3&gt;
&lt;p&gt;Este proyecto es el antes mencionado que se llama Alire pero que no aprovecha nada de este gestor de paquetes. Mi finalidad en este código era explorar tanto la concurrencia como el paralelismo de ADA, el cual, al buscar información sobre otros temas, aparentemente era de los puntos más fuertes que tenía el lenguaje. Lograr que todo funcionara correctamente no fue sencillo; como mencioné anteriormente, los warnings de estilo de Alire, aunque útiles en otros contextos, no ayudaban a identificar los problemas reales de funcionamiento. Sin embargo, con perseverancia, logré construir una simulación funcional de un sistema de tráfico con semáforos y vehículos. A continuación, algunos aspectos destacados del proyecto:&lt;/p&gt;
&lt;ul&gt;
&lt;li&gt;Implementé tareas para los semáforos y los vehículos, de manera que cada uno pudiera monitorear y coordinarse con el estado de los demás.&lt;/li&gt;
&lt;li&gt;Para que los vehículos pudieran cruzar la intersección sin colisiones, usé un tipo protegido llamado &lt;code&gt;Intersection&lt;/code&gt;. Los tipos protegidos en Ada permiten el acceso concurrente controlado a recursos compartidos, lo cual es esencial en sistemas donde múltiples procesos pueden acceder a un mismo recurso.&lt;/li&gt;
&lt;li&gt;Para gestionar el cambio de estados en el semáforo y recibir las solicitudes de los vehículos, utilicé entradas en la tarea &lt;code&gt;TrafficLight&lt;/code&gt; como &lt;code&gt;Change_To_Green&lt;/code&gt; y &lt;code&gt;Change_To_Red&lt;/code&gt;. Mediante la sentencia &lt;code&gt;select&lt;/code&gt;, pude hacer que el semáforo aceptara estas llamadas de entrada según su estado actual.&lt;/li&gt;
&lt;/ul&gt;
&lt;h3 id=&#34;detector-de-movimientohttpsgithubcomgonzalosilvaldeadatreemotion-detection-project&#34;&gt;&lt;a href=&#34;https://github.com/Gonzalosilvalde/ADA/tree/motion-detection-project&#34;&gt;Detector de movimiento&lt;/a&gt;&lt;/h3&gt;
&lt;p&gt;En este proyecto finalmente decidí dejar el uso de Alire para otra ocasión y considerarlo un aprendizaje a futuro. La idea de implementar un detector de movimiento surgió por dos motivos: el primero fue notar, al explorar la página de crates de Alire, que no había algo comparable a OpenCV; el segundo fue recordar un proyecto anterior donde integré código C en Rust usando &lt;code&gt;Cargo&lt;/code&gt;. Si bien esto introdujo código inseguro y un tanto contrario a la filosofía de Rust, fue una buena oportunidad para experimentar. Esta vez quise intentar algo nuevo y explorar las posibilidades de Ada en combinación con &lt;code&gt;OpenCV&lt;/code&gt;.&lt;/p&gt;
&lt;p&gt;Mi enfoque consistió en identificar qué funciones de OpenCV eran necesarias para implementar un detector de movimiento en C++ y, a partir de allí, desarrollar un wrapper que pudiera integrarse con Ada. Este wrapper maneja la creación del detector, la captura de fotogramas y las operaciones de procesamiento de movimiento. A través de &lt;code&gt;pragma Import&lt;/code&gt; expuse las funciones del wrapper de C++ a Ada, permitiéndome trabajar con estas funcionalidades de OpenCV directamente desde el código en Ada. Esta experiencia me ayudó a comprender cómo gestionar la interoperabilidad entre Ada y C++, especialmente en proyectos de cierto nivel de complejidad.&lt;/p&gt;
&lt;p&gt;Durante el desarrollo, también fue clave aprender a coordinar tareas concurrentes. La tarea &lt;code&gt;Save_Motion&lt;/code&gt; se ejecuta en paralelo, guardando los fotogramas que contienen movimiento sin interferir con la captura en tiempo real. Ada facilitó esta estructura mediante el uso de tareas, y aprendí mucho sobre cómo gestionar sistemas en tiempo real. La sincronización de recursos compartidos fue otro desafío que Ada ayudó a simplificar, especialmente al coordinar el acceso seguro a los recursos de OpenCV.&lt;/p&gt;
</content>
    </item>
    
  </channel>
</rss>
